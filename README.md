# ML Showcase - Jack Lucas Chang

A comprehensive portfolio showcasing machine learning and natural language processing projects developed during graduate studies at UC Berkeley's Master of Information and Data Science program.

## Repository Structure

### Core Projects

**ML_Image_Classification.ipynb**
- Multi-label Convolutional Neural Network implementation
- Achieved 82%, 84%, and 98% accuracy across multiple image characteristics
- Real-time image classification and recommendation system using PyTorch and TensorFlow
- Pok√©mon image classification and recommendation based on user uploads

**RAG Final Assignment.ipynb & RAG Report.docx**
- Retrieval-Augmented Generation (RAG) implementation
- Advanced NLP techniques for information retrieval and generation
- Complete project documentation and analysis

### Natural Language Processing Suite

**NLP Scripts Directory**
Comprehensive collection of NLP model training experiments:

1. **Lyrics-Only Training** - Baseline model using lyrical content
2. **Lyrics + Genius Annotations** - Enhanced model with annotation data
3. **Poem + Lyrics Training** - Cross-domain training approach
4. **Multi-Modal Training** - Combining poems, lyrics, and annotations
5. **Pegasus Model** - Advanced transformer architecture on complete dataset
6. **BART Models** - Both base and fine-tuned implementations
7. **T5 Fine-Tuned** - Complete T5 model with results and code
8. **Genius Data Exploration** - Data analysis and preprocessing scripts

**NLP Report.docx**
- Detailed analysis and findings from NLP experiments
- Model comparison and performance metrics
- Research methodology and conclusions

## Key Technical Achievements

- **Deep Learning**: Multi-label CNN classifiers with high accuracy rates
- **NLP Pipeline**: End-to-end text processing from raw data to trained models
- **Model Diversity**: Implementation of BART, T5, and Pegasus transformers
- **Data Integration**: Successfully combined multiple data sources (lyrics, poems, annotations)
- **Performance Optimization**: Fine-tuned models for enhanced accuracy

## Technologies Used

- **Machine Learning**: PyTorch, TensorFlow, Scikit-learn
- **NLP**: Transformers (BART, T5, Pegasus), Named Entity Recognition
- **Data Processing**: Python, Pandas, NumPy
- **Cloud Platforms**: AWS (based on professional experience)
- **Development**: Jupyter Notebooks, Git

## Professional Context

This repository demonstrates practical application of skills developed from:
- **Education**: MS in Information and Data Science (Machine Learning) - UC Berkeley

## Real-World Applications & Impact

Projects demonstrate scalable solutions with measurable business impact:

**Healthcare & Research**
- **Medical Record Digitization**: Converted 17,000+ unstructured veterinary medical records to FHIR using AWS Textract and Healthlake
- **Research Infrastructure**: Supporting $40M+ research projects contributing to 15+ published scientific papers
- **Data Pipeline Optimization**: Achieved 87% reduction in data transformation time for millions of veterinary research records

**Enterprise Systems**
- **Self-Service Analytics**: Reduced manual data requests by 40% through automated reporting platforms
- **A/B Testing Pipeline**: Drove 25% increase in user satisfaction and 20% boost in feature adoption at Microsoft Stream
- **System Reliability**: Maintained 99.9% uptime across enterprise-scale ETL pipelines

---

*This portfolio bridges academic machine learning research with production-ready data engineering solutions, demonstrating expertise in both theoretical foundations and practical implementation at enterprise scale.*
