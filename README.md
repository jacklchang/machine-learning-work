# ML Showcase - Jack Lucas Chang

A comprehensive portfolio showcasing machine learning and natural language processing projects developed during graduate studies at UC Berkeley's Master of Information and Data Science program.

## Repository Structure

### Core Projects

**ML_Image_Classification.ipynb**
- Multi-label Convolutional Neural Network implementation
- Achieved 82%, 84%, and 98% accuracy across multiple image characteristics
- Real-time image classification and recommendation system using PyTorch and TensorFlow
- Pok√©mon image classification and recommendation based on user uploads

**RAG Final Assignment.ipynb & RAG Report.docx**
- Retrieval-Augmented Generation (RAG) implementation
- Advanced NLP techniques for information retrieval and generation
- Complete project documentation and analysis

### Natural Language Processing Suite

**NLP Scripts Directory**
Comprehensive collection of NLP model training experiments:

1. **Lyrics-Only Training** - Baseline model using lyrical content
2. **Lyrics + Genius Annotations** - Enhanced model with annotation data
3. **Poem + Lyrics Training** - Cross-domain training approach
4. **Multi-Modal Training** - Combining poems, lyrics, and annotations
5. **Pegasus Model** - Advanced transformer architecture on complete dataset
6. **BART Models** - Both base and fine-tuned implementations
7. **T5 Fine-Tuned** - Complete T5 model with results and code
8. **Genius Data Exploration** - Data analysis and preprocessing scripts

**NLP Report.docx**
- Detailed analysis and findings from NLP experiments
- Model comparison and performance metrics
- Research methodology and conclusions

## Key Technical Achievements

- **Deep Learning**: Multi-label CNN classifiers with high accuracy rates
- **NLP Pipeline**: End-to-end text processing from raw data to trained models
- **Model Diversity**: Implementation of BART, T5, and Pegasus transformers
- **Data Integration**: Successfully combined multiple data sources (lyrics, poems, annotations)
- **Performance Optimization**: Fine-tuned models for enhanced accuracy

## Technologies Used

- **Machine Learning**: PyTorch, TensorFlow, Scikit-learn
- **NLP**: Transformers (BART, T5, Pegasus)
- **Data Processing**: Python, Pandas, NumPy
- **Cloud Platforms**: AWS (based on professional experience)
- **Development**: Jupyter Notebooks, Git

## Real-World Applications & Impact

Projects demonstrate scalable solutions with measurable business impact:

**Enterprise Data Systems**
- **Large-Scale Data Processing**: Experience with enterprise-scale ETL pipeline architecture and automation
- **Performance Optimization**: Achieved significant reductions in data transformation time for large datasets
- **System Reliability**: Maintained high uptime across production data systems
- **Self-Service Analytics**: Developed automated reporting platforms reducing manual data requests

**Research & Analytics**
- **Cross-Domain Analysis**: Applied machine learning techniques across diverse data sources
- **Statistical Analysis**: Experience with large-scale statistical analysis and pattern recognition
- **Data Integration**: Successfully combined multiple heterogeneous data sources

## Academic Foundation

**University of California, Berkeley** - Master of Information and Data Science (Machine Learning) - 08/2025
**University of Washington, Seattle** - Dual Bachelor's: Informatics (Database Engineering) & Philosophy (Ethics) - 06/2021

## Professional Experience 

**Current Role - Data Engineer (09/2021-present)**
- Enterprise-scale ETL pipeline architecture with Python and automation tools
- Cloud data warehousing with modern analytics platforms
- Self-service analytics platform development
- Cross-functional collaboration on data-driven decision making

---

*This portfolio bridges academic machine learning research with production-ready data engineering solutions, demonstrating expertise in both theoretical foundations and practical implementation at enterprise scale.*
