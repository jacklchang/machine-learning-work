{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r0aGw5WC3EQJ"
   },
   "source": [
    "# BERT Fine Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MlH1trW-xxyh"
   },
   "source": [
    "# Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6878,
     "status": "ok",
     "timestamp": 1733642555507,
     "user": {
      "displayName": "Sahana S",
      "userId": "09133778862757081963"
     },
     "user_tz": 480
    },
    "id": "Vi4g8YjN-3nF",
    "outputId": "0b159d70-ca28-497d-9272-26477766820c"
   },
   "outputs": [],
   "source": [
    "!pip install googletrans==4.0.0-rc1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15318,
     "status": "ok",
     "timestamp": 1733642613868,
     "user": {
      "displayName": "Sahana S",
      "userId": "09133778862757081963"
     },
     "user_tz": 480
    },
    "id": "1jV636rJ-hDV",
    "outputId": "8e0a523b-81e4-417e-94d9-89c7387f7405"
   },
   "outputs": [],
   "source": [
    "!pip install pytorch-lightning\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "#translation and eval\n",
    "from googletrans import Translator\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28608,
     "status": "ok",
     "timestamp": 1733642867882,
     "user": {
      "displayName": "Sahana S",
      "userId": "09133778862757081963"
     },
     "user_tz": 480
    },
    "id": "s8nwDBy-J0VX",
    "outputId": "2ac81b9c-0b86-4bca-dd1b-a7267eec373f"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lUEeWPRg_D6G"
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "import torch\n",
    "\n",
    "# Path to saved model\n",
    "model_path = '/content/drive/MyDrive/266 Final Project/Our Models/BART_All_Data'\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = BartTokenizer.from_pretrained(model_path)\n",
    "model = BartForConditionalGeneration.from_pretrained(model_path)\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rYyqJouzx95D"
   },
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 51296,
     "status": "ok",
     "timestamp": 1733642941265,
     "user": {
      "displayName": "Sahana S",
      "userId": "09133778862757081963"
     },
     "user_tz": 480
    },
    "id": "u1Rxzgku_FEl",
    "outputId": "81b2871f-1f39-4ce9-f6da-d23261619422"
   },
   "outputs": [],
   "source": [
    "# Load lyrics data\n",
    "print(\"Loading lyrics data from Google Drive...\")\n",
    "df_list = []\n",
    "lyrics_folder_path = \"/content/drive/My Drive/266 Final Project/Song Files\"\n",
    "for filename in os.listdir(lyrics_folder_path):\n",
    "    if filename.endswith('.csv'):\n",
    "        file_path = os.path.join(lyrics_folder_path, filename)\n",
    "        df = pd.read_csv(file_path)\n",
    "        df_list.append(df)\n",
    "\n",
    "lyrics_df = pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2346,
     "status": "ok",
     "timestamp": 1733642943608,
     "user": {
      "displayName": "Sahana S",
      "userId": "09133778862757081963"
     },
     "user_tz": 480
    },
    "id": "tArb3_h-_QQv",
    "outputId": "94ac871c-43ff-447b-d29d-23b520e27b3f"
   },
   "outputs": [],
   "source": [
    "# Load poetry data\n",
    "print(\"\\nLoading poetry data...\")\n",
    "poem_list = []\n",
    "poetry_files = {\n",
    "    'test': \"/content/drive/My Drive/266 Final Project/PoemSum Model/poemsum_test.csv\",\n",
    "    'train': \"/content/drive/My Drive/266 Final Project/PoemSum Model/poemsum_train.csv\",\n",
    "    'valid': \"/content/drive/My Drive/266 Final Project/PoemSum Model/poemsum_valid.csv\"\n",
    "}\n",
    "\n",
    "for dataset_type, filepath in poetry_files.items():\n",
    "    print(f\"Loading poetry {dataset_type} dataset\")\n",
    "    poem_data = pd.read_csv(filepath)\n",
    "    poem_list.append(poem_data)\n",
    "\n",
    "poem_df = pd.concat(poem_list, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1733642943608,
     "user": {
      "displayName": "Sahana S",
      "userId": "09133778862757081963"
     },
     "user_tz": 480
    },
    "id": "ZUZM75Zl_L9r",
    "outputId": "48ce00e3-4b9f-4dbf-8e3e-fb20120476c4"
   },
   "outputs": [],
   "source": [
    "# Split datasets\n",
    "print(\"\\nSplitting datasets...\")\n",
    "train_val_df, test_df = train_test_split(lyrics_df, test_size=0.2, random_state=42)\n",
    "train_val_poem, test_poem = train_test_split(poem_df, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Lyrics data split - Training+Validation: {len(train_val_df)}, Test: {len(test_df)}\")\n",
    "print(f\"Poetry data split - Training+Validation: {len(train_val_poem)}, Test: {len(test_poem)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IinxHfrcyH1K"
   },
   "source": [
    "# Data Augmentation Experiment Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3fIPWrmi_foA"
   },
   "outputs": [],
   "source": [
    "# Data Augmentation Functions\n",
    "def backtranslate(text: str, src_lang: str = \"en\", tgt_lang: str = \"fr\") -> str:\n",
    "    \"\"\"Perform backtranslation using Google Translate.\"\"\"\n",
    "    translator = Translator()\n",
    "    try:\n",
    "        translated = translator.translate(text, src=src_lang, dest=tgt_lang).text\n",
    "        back_translated = translator.translate(translated, src=tgt_lang, dest=src_lang).text\n",
    "        return back_translated\n",
    "    except Exception as e:\n",
    "        print(f\"Backtranslation error: {e}\")\n",
    "        return text\n",
    "\n",
    "def synonym_replacement(text: str, synonym_dict: dict) -> str:\n",
    "    \"\"\"Replace words in text with synonyms.\"\"\"\n",
    "    words = text.split()\n",
    "    augmented_text = \" \".join([synonym_dict.get(word, word) for word in words])\n",
    "    return augmented_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "deuPQfHlyZFJ"
   },
   "source": [
    "# Data Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5hTyVJCu_juB"
   },
   "outputs": [],
   "source": [
    "class BARTDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, train_df, val_df=None, tokenizer=None, batch_size=16, max_length=512, augment=False):\n",
    "        super().__init__()\n",
    "        self.train_df = train_df\n",
    "        self.val_df = val_df  # Validation data is optional\n",
    "        self.tokenizer = tokenizer\n",
    "        self.batch_size = batch_size\n",
    "        self.max_length = max_length\n",
    "        self.augment = augment\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        if self.augment:\n",
    "            synonym_dict = {\"example\": \"sample\", \"text\": \"content\"}  # Example synonym dictionary\n",
    "            self.train_df['source'] = self.train_df['source'].apply(\n",
    "                lambda x: backtranslate(x) if np.random.rand() < 0.3 else synonym_replacement(x, synonym_dict)\n",
    "            )\n",
    "        self.train_encodings = self._encode_data(self.train_df)\n",
    "        if self.val_df is not None:\n",
    "            self.val_encodings = self._encode_data(self.val_df)\n",
    "\n",
    "    def _encode_data(self, df):\n",
    "        df['target'] = df['target'].astype(str)  # Ensure 'target' column is of string type\n",
    "        df['target'] = df['target'].apply(lambda x: x if isinstance(x, str) else str(x)) #Convert non-string values\n",
    "\n",
    "        target_encodings = self.tokenizer(\n",
    "            df['target'].tolist(),\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        source_encodings = self.tokenizer(\n",
    "            df['source'].tolist(),\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        target_encodings = self.tokenizer(\n",
    "            df['target'].tolist(),\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': source_encodings['input_ids'],\n",
    "            'attention_mask': source_encodings['attention_mask'],\n",
    "            'labels': target_encodings['input_ids']\n",
    "        }\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        dataset = TensorDataset(\n",
    "            self.train_encodings['input_ids'],\n",
    "            self.train_encodings['attention_mask'],\n",
    "            self.train_encodings['labels']\n",
    "        )\n",
    "        return DataLoader(dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        # Provide a dummy DataLoader if validation data is not available\n",
    "        if self.val_df is None:\n",
    "            return None\n",
    "        dataset = TensorDataset(\n",
    "            self.val_encodings['input_ids'],\n",
    "            self.val_encodings['attention_mask'],\n",
    "            self.val_encodings['labels']\n",
    "        )\n",
    "        return DataLoader(dataset, batch_size=self.batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kX53EY32ydPp"
   },
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zVXmzV-A_l_z"
   },
   "outputs": [],
   "source": [
    "# Define Model\n",
    "class BARTLitModel(pl.LightningModule):\n",
    "    def __init__(self, model, learning_rate=2e-5, use_label_smoothing=False, smoothing=0.1):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.learning_rate = learning_rate\n",
    "        self.use_label_smoothing = use_label_smoothing\n",
    "        self.smoothing = smoothing\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        outputs = self.model(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "        return outputs\n",
    "\n",
    "    def label_smoothing_loss(self, logits, labels):\n",
    "        # Implement label smoothing\n",
    "        vocab_size = logits.size(-1)\n",
    "        one_hot = torch.nn.functional.one_hot(labels, num_classes=vocab_size).float()\n",
    "        smoothed_labels = one_hot * (1 - self.smoothing) + (self.smoothing / vocab_size)\n",
    "        log_probs = torch.nn.functional.log_softmax(logits, dim=-1)\n",
    "        loss = -(smoothed_labels * log_probs).sum(dim=-1).mean()\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        outputs = self(input_ids, attention_mask, labels)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        # Apply label smoothing if enabled\n",
    "        if self.use_label_smoothing:\n",
    "            loss = self.label_smoothing_loss(outputs.logits, labels)\n",
    "\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        outputs = self(input_ids, attention_mask, labels)\n",
    "        val_loss = outputs.loss\n",
    "\n",
    "        self.log('val_loss', val_loss)\n",
    "        return val_loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.parameters(), lr=self.learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bu8SNnGmygUw"
   },
   "source": [
    "# Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9aXIpT89_o70"
   },
   "outputs": [],
   "source": [
    "# Experiment Runner\n",
    "def run_experiment(\n",
    "    experiment_name,\n",
    "    train_df,\n",
    "    val_df,\n",
    "    model,\n",
    "    tokenizer,\n",
    "    batch_size,\n",
    "    max_length,\n",
    "    learning_rate,\n",
    "    drive_path,\n",
    "    augment=False,\n",
    "    use_label_smoothing=False\n",
    "):\n",
    "    print(f\"Running Experiment: {experiment_name}\")\n",
    "\n",
    "\n",
    "    # Set up experiment directory in Google Drive\n",
    "    experiment_dir = os.path.join(drive_path, experiment_name.replace(\" \", \"_\"))\n",
    "    os.makedirs(experiment_dir, exist_ok=True)\n",
    "\n",
    "    # Initialize data module with augmentation logic\n",
    "    data_module = BARTDataModule(\n",
    "        train_df=train_df,\n",
    "        val_df=val_df,\n",
    "        tokenizer=tokenizer,\n",
    "        batch_size=batch_size,\n",
    "        max_length=max_length,\n",
    "        augment=augment\n",
    "    )\n",
    "\n",
    "    # Initialize Lightning module with label smoothing logic\n",
    "    bart_model = BARTLitModel(model=model, learning_rate=learning_rate, use_label_smoothing=use_label_smoothing)\n",
    "\n",
    "    # Set up Trainer\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=3,\n",
    "        devices=1 if torch.cuda.is_available() else None,\n",
    "        accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "        gradient_clip_val=1.0,\n",
    "        log_every_n_steps=10,\n",
    "        default_root_dir=experiment_dir,\n",
    "        enable_checkpointing=False  # Disable validation-based checkpointing\n",
    "    )\n",
    "\n",
    "\n",
    "    # Fine-tune the model\n",
    "    trainer.fit(bart_model, datamodule=data_module)\n",
    "\n",
    "    # Save the model and tokenizer\n",
    "    model_save_path = os.path.join(experiment_dir, \"fine_tuned_model\")\n",
    "    tokenizer_save_path = os.path.join(experiment_dir, \"fine_tuned_tokenizer\")\n",
    "    bart_model.model.save_pretrained(model_save_path)\n",
    "    tokenizer.save_pretrained(tokenizer_save_path)\n",
    "\n",
    "    print(f\"Experiment '{experiment_name}' results saved to {experiment_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "izCbTgcFBMkW"
   },
   "outputs": [],
   "source": [
    "# Rename columns in train_val_df and test_df\n",
    "train_val_df.rename(columns={\"Lyrics\": \"source\", \"Combined Annotations\": \"target\"}, inplace=True)\n",
    "test_df.rename(columns={\"Lyrics\": \"source\", \"Combined Annotations\": \"target\"}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1733642943608,
     "user": {
      "displayName": "Sahana S",
      "userId": "09133778862757081963"
     },
     "user_tz": 480
    },
    "id": "TMNYqHtKBiOz",
    "outputId": "17c26100-1f83-42a4-ce82-88286b010381"
   },
   "outputs": [],
   "source": [
    "# Check for any problematic values\n",
    "print(train_val_df['source'].isnull().sum())  # Check for null values\n",
    "print(train_val_df['source'].apply(lambda x: isinstance(x, str)).value_counts())  # Check if all are strings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jns7aWYzCME5"
   },
   "outputs": [],
   "source": [
    "def is_tokenizable(text):\n",
    "    try:\n",
    "        # Attempt tokenization\n",
    "        tokenizer(text, padding=True, truncation=True, max_length=512, return_tensors='pt')\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zmLJQgdTCMrY"
   },
   "outputs": [],
   "source": [
    "# Apply the validation function\n",
    "train_val_df['is_valid'] = train_val_df['source'].apply(is_tokenizable)\n",
    "\n",
    "# Filter out invalid rows\n",
    "valid_train_val_df = train_val_df[train_val_df['is_valid']].drop(columns=['is_valid'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t3Hl4Uc4CkHF"
   },
   "outputs": [],
   "source": [
    "test_df['is_valid'] = test_df['source'].apply(is_tokenizable)\n",
    "valid_test_df = test_df[test_df['is_valid']].drop(columns=['is_valid'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1733642952550,
     "user": {
      "displayName": "Sahana S",
      "userId": "09133778862757081963"
     },
     "user_tz": 480
    },
    "id": "QpQq7lYaCneM",
    "outputId": "2edac807-ff20-45bd-ef34-fa5119e72627"
   },
   "outputs": [],
   "source": [
    "print(f\"Original training rows: {len(train_val_df)}\")\n",
    "print(f\"Valid training rows: {len(valid_train_val_df)}\")\n",
    "print(f\"Removed rows: {len(train_val_df) - len(valid_train_val_df)}\")\n",
    "\n",
    "print(f\"Original test rows: {len(test_df)}\")\n",
    "print(f\"Valid test rows: {len(valid_test_df)}\")\n",
    "print(f\"Removed rows: {len(test_df) - len(valid_test_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 935,
     "referenced_widgets": [
      "68f85296ce91429b87a8e8ac239b9c22",
      "9f5fe20e905145f49e7fc057f553e82e",
      "dd0939540863411e81579622819f579c",
      "8cc80cf4c2a641e7a715b6f3295862c1",
      "c3891c72d2844331a225ec4cd0024332",
      "d04d00b94a874e689621394ad560c65a",
      "46c560ca9fb649b4bbbebc78930ef951",
      "46a771836bce4670b8775e658bb55dbb",
      "b1677988c9e747639cac087311805dae",
      "7114a7fcc1ea4eea867d741ef6f5e762",
      "b649b6baf1744ef1a90e4ab78312b98c",
      "30893a4d61c547b6bac48d2fd81be4da",
      "ae64a788be92424996b1700e10cde4b3",
      "57960d2d5e0a47dea5e9ee14be94fd78",
      "ac90c5c5687e41a89c4808dc0468d188",
      "83b5bc42260d4ee2a42eacb589011c26",
      "33b3ffa581c14eac8d31962038d4151f",
      "446c9ba1505042319cc17bc2736e9697",
      "426d28dcd2fd44cbb4606da8ba677f6e",
      "6a58de6976e843a490c81acc7ce96a0e",
      "7d829babd3be486db9949075e1647e17",
      "1c52d16c5ab04a7f80ab6c59b08e32b2"
     ]
    },
    "executionInfo": {
     "elapsed": 18532,
     "status": "error",
     "timestamp": 1733643015572,
     "user": {
      "displayName": "Sahana S",
      "userId": "09133778862757081963"
     },
     "user_tz": 480
    },
    "id": "NV2IvsQZ_uL0",
    "outputId": "01e20aaa-ee19-44d7-ff7f-5a83c3c9da0e"
   },
   "outputs": [],
   "source": [
    "# Define Experiments\n",
    "#could not run last experiment due to memory loss\n",
    "experiments = [\n",
    "    #{\"name\": \"Base Fine-Tuning\", \"batch_size\": 16, \"max_length\": 512, \"learning_rate\": 2e-5},\n",
    "    {\"name\": \"Hyperparameter Tuning\", \"batch_size\": 8, \"max_length\": 256, \"learning_rate\": 5e-5},\n",
    "    {\"name\": \"Data Augmentation\", \"batch_size\": 16, \"max_length\": 512, \"learning_rate\": 2e-5, \"augment\": True},\n",
    "    #{\"name\": \"Loss Function Experiment\", \"batch_size\": 16, \"max_length\": 512, \"learning_rate\": 2e-5, \"use_label_smoothing\": True}\n",
    "]\n",
    "\n",
    "# Set Drive Path\n",
    "drive_path = \"/content/drive/MyDrive/266 Final Project/Our Models/BART Fine Tuned\"\n",
    "\n",
    "# Run Experiments\n",
    "for exp in experiments:\n",
    "    # Pass a subset of the training data as validation data\n",
    "    train_data, val_data = train_test_split(valid_train_val_df, test_size=0.2, random_state=42)\n",
    "    run_experiment(\n",
    "        experiment_name=exp[\"name\"],\n",
    "        train_df=train_data,\n",
    "        val_df=val_data,\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        batch_size=exp[\"batch_size\"],\n",
    "        max_length=exp[\"max_length\"],\n",
    "        learning_rate=exp[\"learning_rate\"],\n",
    "        drive_path=drive_path,\n",
    "        augment=exp.get(\"augment\", False),\n",
    "        use_label_smoothing=exp.get(\"use_label_smoothing\", False)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1UbO3nVmWjIt"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 3075,
     "status": "error",
     "timestamp": 1733643041974,
     "user": {
      "displayName": "Sahana S",
      "userId": "09133778862757081963"
     },
     "user_tz": 480
    },
    "id": "bATjSH24Ubiw",
    "outputId": "abebe076-f004-4fe6-edce-b11988fa0507"
   },
   "outputs": [],
   "source": [
    "!pip install bert_score\n",
    "from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from typing import Dict, List, Tuple\n",
    "from bert_score import score\n",
    "from rouge_score import rouge_scorer\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 521
    },
    "executionInfo": {
     "elapsed": 272,
     "status": "ok",
     "timestamp": 1733643044952,
     "user": {
      "displayName": "Sahana S",
      "userId": "09133778862757081963"
     },
     "user_tz": 480
    },
    "id": "b-94-Deybndx",
    "outputId": "6cb24199-20c5-410f-f599-b7e8343d7d0b"
   },
   "outputs": [],
   "source": [
    "#checkinf test df\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 848,
     "status": "ok",
     "timestamp": 1733643047756,
     "user": {
      "displayName": "Sahana S",
      "userId": "09133778862757081963"
     },
     "user_tz": 480
    },
    "id": "cm5tEsR4d5-3",
    "outputId": "c266349b-e1f3-4535-8d0f-debc2d3151b5"
   },
   "outputs": [],
   "source": [
    "# Check for NaN values\n",
    "print(\"NaN values in test_df:\")\n",
    "print(test_df.isna().sum())\n",
    "\n",
    "# Check data types\n",
    "print(\"\\nData types:\")\n",
    "print(test_df.dtypes)\n",
    "\n",
    "# Clean the data\n",
    "test_df['source'] = test_df['source'].fillna('')\n",
    "test_df['target'] = test_df['target'].fillna('')\n",
    "\n",
    "# Convert to string type\n",
    "test_df['source'] = test_df['source'].astype(str)\n",
    "test_df['target'] = test_df['target'].astype(str)\n",
    "\n",
    "# Verify no empty strings that might cause issues\n",
    "print(\"\\nNumber of empty lyrics:\", len(test_df[test_df['source'] == '']))\n",
    "print(\"Number of empty annotations:\", len(test_df[test_df['target'] == '']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1733643049655,
     "user": {
      "displayName": "Sahana S",
      "userId": "09133778862757081963"
     },
     "user_tz": 480
    },
    "id": "MXbHT4cgeCdC",
    "outputId": "09793a9d-2929-411d-cc13-588eba5e2c49"
   },
   "outputs": [],
   "source": [
    "# Initial data cleanup\n",
    "print(\"Initial data shape:\", test_df.shape)\n",
    "\n",
    "# Fill NaN values\n",
    "test_df['target'] = test_df['target'].fillna('')\n",
    "\n",
    "# Convert source and target to string type\n",
    "test_df['source'] = test_df['source'].astype(str)\n",
    "test_df['target'] = test_df['target'].astype(str)\n",
    "\n",
    "# Remove rows where either source or target is empty (optional)\n",
    "# test_df = test_df[test_df['source'].str.strip() != '']\n",
    "# test_df = test_df[test_df['target'].str.strip() != '']\n",
    "\n",
    "# Double check the cleaned data\n",
    "print(\"\\nAfter cleaning:\")\n",
    "print(\"Number of empty lyrics:\", len(test_df[test_df['source'] == '']))\n",
    "print(\"Number of empty annotations:\", len(test_df[test_df['target'] == '']))\n",
    "print(\"Final data shape:\", test_df.shape)\n",
    "\n",
    "# Verify a few examples\n",
    "print(\"\\nSample data check:\")\n",
    "print(test_df[['source', 'target']].head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_9FpgGXiVqS4"
   },
   "outputs": [],
   "source": [
    "def evaluate_supervised_model(\n",
    "    model: BartForConditionalGeneration,\n",
    "    tokenizer: BartTokenizer,\n",
    "    test_data: pd.DataFrame,\n",
    "    batch_size: int = 16\n",
    ") -> Tuple[Dict[str, float], List[Dict]]:\n",
    "    \"\"\"\n",
    "    Evaluate supervised lyrics model comparing against Genius annotations using BART\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "\n",
    "    evaluation_results = {\n",
    "        'content_coverage': [],\n",
    "        'consistency_score': [],\n",
    "        'semantic_similarity': [],\n",
    "        'rouge1_scores': [],\n",
    "        'rouge2_scores': [],\n",
    "        'rougeL_scores': [],\n",
    "        'bert_scores': []\n",
    "    }\n",
    "\n",
    "    examples = []\n",
    "    previous_bert_score = 0.0\n",
    "\n",
    "    for idx in tqdm(range(0, len(test_data), batch_size)):\n",
    "        batch_lyrics = test_data['source'].iloc[idx:idx + batch_size].tolist()\n",
    "        batch_annotations = test_data['target'].iloc[idx:idx + batch_size].tolist()\n",
    "\n",
    "        # Generate summaries (BART-specific encoding)\n",
    "        inputs = tokenizer(\n",
    "            [f\"summarize lyrics and capture meaning: {lyric}\" for lyric in batch_lyrics],\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=1024,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                input_ids=inputs['input_ids'],\n",
    "                attention_mask=inputs['attention_mask'],\n",
    "                max_length=150,\n",
    "                min_length=50,\n",
    "                num_beams=4,\n",
    "                do_sample=True,\n",
    "                temperature=0.7,\n",
    "                top_k=50,\n",
    "                no_repeat_ngram_size=3,\n",
    "                length_penalty=1.0,\n",
    "                repetition_penalty=1.2\n",
    "            )\n",
    "\n",
    "            generated_summaries = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "\n",
    "        # Evaluate each summary against its reference annotation\n",
    "        for i in range(len(generated_summaries)):\n",
    "            original_lyric = batch_lyrics[i]\n",
    "            generated_summary = generated_summaries[i]\n",
    "            reference_annotation = batch_annotations[i]\n",
    "\n",
    "            # Content Coverage (between summary and lyrics)\n",
    "            coverage_score = calculate_content_coverage(original_lyric, generated_summary)\n",
    "            evaluation_results['content_coverage'].append(coverage_score)\n",
    "\n",
    "            # Semantic Similarity (between summary and lyrics)\n",
    "            semantic_score = calculate_semantic_similarity(original_lyric, generated_summary)\n",
    "            evaluation_results['semantic_similarity'].append(semantic_score)\n",
    "\n",
    "            # ROUGE Scores (between generated summary and reference annotation)\n",
    "            rouge_scores = calculate_rouge_scores([generated_summary, reference_annotation])\n",
    "            evaluation_results['rouge1_scores'].append(rouge_scores['rouge1'])\n",
    "            evaluation_results['rouge2_scores'].append(rouge_scores['rouge2'])\n",
    "            evaluation_results['rougeL_scores'].append(rouge_scores['rougeL'])\n",
    "\n",
    "            # BERTScore (between generated summary and reference annotation)\n",
    "            if i % 8 == 0:  # Compute less frequently to save time\n",
    "                P, R, F1 = score([generated_summary], [reference_annotation], lang='en', verbose=False)\n",
    "                previous_bert_score = F1.mean().item()\n",
    "            evaluation_results['bert_scores'].append(previous_bert_score)\n",
    "\n",
    "            # Store examples\n",
    "            if len(examples) < 5:\n",
    "                examples.append({\n",
    "                    'lyrics': original_lyric,\n",
    "                    'reference_annotation': reference_annotation,\n",
    "                    'generated_summary': generated_summary,\n",
    "                    'metrics': {\n",
    "                        'content_coverage': coverage_score,\n",
    "                        'semantic_similarity': semantic_score,\n",
    "                        'rouge1': rouge_scores['rouge1'],\n",
    "                        'rouge2': rouge_scores['rouge2'],\n",
    "                        'rougeL': rouge_scores['rougeL'],\n",
    "                        'bert_score': previous_bert_score\n",
    "                    }\n",
    "                })\n",
    "\n",
    "        # Memory cleanup\n",
    "        if idx % 5 == 0:\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    # Aggregate results\n",
    "    metrics = {\n",
    "        'avg_content_coverage': np.mean(evaluation_results['content_coverage']),\n",
    "        'avg_semantic_similarity': np.mean(evaluation_results['semantic_similarity']),\n",
    "        'avg_rouge1': np.mean(evaluation_results['rouge1_scores']),\n",
    "        'avg_rouge2': np.mean(evaluation_results['rouge2_scores']),\n",
    "        'avg_rougeL': np.mean(evaluation_results['rougeL_scores']),\n",
    "        'avg_bert_score': np.mean(evaluation_results['bert_scores'])\n",
    "    }\n",
    "\n",
    "    return metrics, examples\n",
    "\n",
    "def calculate_rouge_scores(texts: List[str]) -> Dict[str, float]:\n",
    "    \"\"\"Calculate ROUGE scores between texts\"\"\"\n",
    "    rouge_scorer_obj = rouge_scorer.RougeScorer(\n",
    "        ['rouge1', 'rouge2', 'rougeL'],\n",
    "        use_stemmer=True\n",
    "    )\n",
    "    score = rouge_scorer_obj.score(texts[0], texts[1])\n",
    "    return {\n",
    "        'rouge1': score['rouge1'].fmeasure,\n",
    "        'rouge2': score['rouge2'].fmeasure,\n",
    "        'rougeL': score['rougeL'].fmeasure\n",
    "    }\n",
    "\n",
    "def calculate_content_coverage(lyrics: str, summary: str) -> float:\n",
    "    \"\"\"Calculate content coverage between lyrics and summary\"\"\"\n",
    "    if isinstance(lyrics, float) or isinstance(summary, float):\n",
    "        return 0.0\n",
    "\n",
    "    try:\n",
    "        lyrics_tokens = set(str(lyrics).lower().split())\n",
    "        summary_tokens = set(str(summary).lower().split())\n",
    "        overlap = len(lyrics_tokens.intersection(summary_tokens))\n",
    "        coverage = overlap / len(lyrics_tokens) if lyrics_tokens else 0.0\n",
    "        return coverage\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing lyrics/summary: {e}\")\n",
    "        return 0.0\n",
    "\n",
    "def calculate_semantic_similarity(lyrics: str, summary: str) -> float:\n",
    "    \"\"\"Calculate semantic similarity using token overlap\"\"\"\n",
    "    if isinstance(lyrics, float) or isinstance(summary, float):\n",
    "        return 0.0\n",
    "\n",
    "    try:\n",
    "        lyrics_tokens = set(str(lyrics).lower().split())\n",
    "        summary_tokens = set(str(summary).lower().split())\n",
    "        intersection = len(lyrics_tokens.intersection(summary_tokens))\n",
    "        union = len(lyrics_tokens.union(summary_tokens))\n",
    "        return intersection / union if union > 0 else 0.0\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing lyrics/summary: {e}\")\n",
    "        return 0.0\n",
    "\n",
    "def print_evaluation_results(metrics: Dict[str, float], examples: List[Dict]):\n",
    "    \"\"\"Print evaluation results and examples\"\"\"\n",
    "    print(\"\\nEvaluation Results:\")\n",
    "    print(f\"Average Content Coverage: {metrics['avg_content_coverage']:.3f}\")\n",
    "    print(f\"Average Semantic Similarity: {metrics['avg_semantic_similarity']:.3f}\")\n",
    "    print(f\"Average ROUGE-1: {metrics['avg_rouge1']:.3f}\")\n",
    "    print(f\"Average ROUGE-2: {metrics['avg_rouge2']:.3f}\")\n",
    "    print(f\"Average ROUGE-L: {metrics['avg_rougeL']:.3f}\")\n",
    "    print(f\"Average BERTScore: {metrics['avg_bert_score']:.3f}\")\n",
    "\n",
    "    print(\"\\nExample Generations:\")\n",
    "    for i, example in enumerate(examples, 1):\n",
    "        print(f\"\\nExample {i}:\")\n",
    "        print(f\"Original Lyrics (truncated): {example['lyrics'][:200]}...\")\n",
    "        print(f\"\\nReference Annotation: {example['reference_annotation']}\")\n",
    "        print(f\"\\nGenerated Summary: {example['generated_summary']}\")\n",
    "        print(\"\\nMetrics:\")\n",
    "        for metric, value in example['metrics'].items():\n",
    "            print(f\"{metric}: {value:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ee1mUo63W34k"
   },
   "outputs": [],
   "source": [
    "def run_evaluation(model_path: str, tokenizer_path: str, test_df: pd.DataFrame, save_dir: str):\n",
    "    \"\"\"\n",
    "    Run evaluation and save results for a given model and tokenizer path.\n",
    "    Results are saved in CSV format.\n",
    "    \"\"\"\n",
    "    tokenizer = BartTokenizer.from_pretrained(tokenizer_path)\n",
    "    model = BartForConditionalGeneration.from_pretrained(model_path)\n",
    "    print(f\"Model loaded from {model_path}, tokenizer loaded from {tokenizer_path}!\")\n",
    "\n",
    "    metrics, examples = evaluate_supervised_model(\n",
    "        model,\n",
    "        tokenizer,\n",
    "        test_data=test_df,\n",
    "        batch_size=16\n",
    "    )\n",
    "\n",
    "    # Create save directory if it doesn't exist\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    # Save metrics to CSV\n",
    "    metrics_df = pd.DataFrame([metrics])\n",
    "    metrics_file = os.path.join(save_dir, \"evaluation_metrics.csv\")\n",
    "    metrics_df.to_csv(metrics_file, index=False)\n",
    "    print(f\"Saved evaluation metrics to: {metrics_file}\")\n",
    "\n",
    "    # Save examples to CSV\n",
    "    examples_df = pd.DataFrame(examples)\n",
    "    examples_file = os.path.join(save_dir, \"evaluation_examples.csv\")\n",
    "    examples_df.to_csv(examples_file, index=False)\n",
    "    print(f\"Saved evaluation examples to: {examples_file}\")\n",
    "\n",
    "    return metrics, examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o00OiQtay258"
   },
   "source": [
    "# Evaluation code for one song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 858,
     "status": "ok",
     "timestamp": 1733643495136,
     "user": {
      "displayName": "Sahana S",
      "userId": "09133778862757081963"
     },
     "user_tz": 480
    },
    "id": "2A2_N6rvK9-D",
    "outputId": "720e396f-4aa4-461f-9e42-d171d5dd93e1"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "import pandas as pd\n",
    "\n",
    "# Define paths\n",
    "root_path = \"/content/drive/MyDrive/266 Final Project/Our Models/BART Fine Tuned\"\n",
    "output_path = \"/content/drive/MyDrive/266 Final Project/Evaluation Results\"\n",
    "\n",
    "# List of experiment directories\n",
    "experiment_dirs = [\n",
    "    os.path.join(root_path, \"Base_Fine-Tuning\"),\n",
    "    os.path.join(root_path, \"Data_Augmentation\"),\n",
    "    os.path.join(root_path, \"Hyperparameter_Tuning\")\n",
    "]\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "# Assuming `test_df` is already loaded as a DataFrame\n",
    "# Replace with the actual loading method if needed (e.g., pd.read_csv)\n",
    "\n",
    "# Find song ID 141615 in the test dataset\n",
    "song_id = 141615\n",
    "song_row = test_df[test_df['Song ID'] == song_id]\n",
    "\n",
    "if song_row.empty:\n",
    "    print(f\"Song ID {song_id} not found in the test dataset.\")\n",
    "else:\n",
    "    lyrics = song_row.iloc[0]['Lyrics']  # Adjust 'Lyrics' column name as necessary\n",
    "    print(f\"Running evaluation for Song ID {song_id}...\\n\")\n",
    "\n",
    "    # Iterate over experiment directories\n",
    "    for experiment_dir in experiment_dirs:\n",
    "        print(f\"Evaluating model from: {experiment_dir}\")\n",
    "\n",
    "        # Load tokenizer and model\n",
    "        tokenizer = BartTokenizer.from_pretrained(experiment_dir)\n",
    "        model = BartForConditionalGeneration.from_pretrained(experiment_dir)\n",
    "\n",
    "        # Tokenize the lyrics\n",
    "        inputs = tokenizer(lyrics, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "\n",
    "        # Generate annotation\n",
    "        outputs = model.generate(inputs['input_ids'], max_length=150, num_beams=5, early_stopping=True)\n",
    "        generated_annotation = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "        # Print the generated annotation\n",
    "        print(f\"Generated Annotation for Song ID {song_id} from {os.path.basename(experiment_dir)}:\\n{generated_annotation}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pIyQrKHKy8ae"
   },
   "source": [
    "# Evaluation code for test df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1230184,
     "status": "ok",
     "timestamp": 1733615629326,
     "user": {
      "displayName": "Sahana S",
      "userId": "09133778862757081963"
     },
     "user_tz": 480
    },
    "id": "TA3mT4mgW-pb",
    "outputId": "80efcf81-46af-4309-ace5-637f41d4af88"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "from tqdm import tqdm\n",
    "from typing import Dict, List, Tuple\n",
    "from bert_score import score\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "# Define paths\n",
    "root_path = \"/content/drive/MyDrive/266 Final Project/Our Models/BART Fine Tuned\"\n",
    "output_path = \"/content/drive/MyDrive/266 Final Project/Evaluation Results\"\n",
    "\n",
    "# List of experiment directories\n",
    "experiment_dirs = [\n",
    "    os.path.join(root_path, \"Base_Fine-Tuning\"),\n",
    "    os.path.join(root_path, \"Data_Augmentation\"),\n",
    "    os.path.join(root_path, \"Hyperparameter_Tuning\")\n",
    "]\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "def run_evaluation(model_path: str, tokenizer_path: str, test_df: pd.DataFrame, save_dir: str):\n",
    "    \"\"\"Run evaluation and save results for a given model and tokenizer path\"\"\"\n",
    "    # Load model and tokenizer\n",
    "    tokenizer = BartTokenizer.from_pretrained(tokenizer_path)\n",
    "    model = BartForConditionalGeneration.from_pretrained(model_path)\n",
    "    print(f\"Model loaded from {model_path}, tokenizer loaded from {tokenizer_path}!\")\n",
    "\n",
    "    # Run evaluation\n",
    "    metrics, examples = evaluate_supervised_model(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        test_data=test_df,\n",
    "        batch_size=16\n",
    "    )\n",
    "\n",
    "    # Create save directory\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    # Save metrics to CSV\n",
    "    metrics_df = pd.DataFrame([metrics])\n",
    "    metrics_csv_path = os.path.join(save_dir, \"evaluation_metrics.csv\")\n",
    "    metrics_df.to_csv(metrics_csv_path, index=False)\n",
    "    print(f\"Metrics saved to {metrics_csv_path}\")\n",
    "\n",
    "    # Save examples to CSV\n",
    "    examples_df = pd.DataFrame(examples)\n",
    "    examples_csv_path = os.path.join(save_dir, \"evaluation_examples.csv\")\n",
    "    examples_df.to_csv(examples_csv_path, index=False)\n",
    "    print(f\"Examples saved to {examples_csv_path}\")\n",
    "\n",
    "    return metrics, examples\n",
    "\n",
    "# Evaluate each experiment\n",
    "for experiment_dir in experiment_dirs:\n",
    "    experiment_name = os.path.basename(experiment_dir)\n",
    "    model_path = os.path.join(experiment_dir, \"fine_tuned_model\")\n",
    "    tokenizer_path = os.path.join(experiment_dir, \"fine_tuned_tokenizer\")\n",
    "    save_dir = os.path.join(output_path, experiment_name)\n",
    "\n",
    "    print(f\"\\nEvaluating experiment: {experiment_name}\")\n",
    "\n",
    "    try:\n",
    "        metrics, examples = run_evaluation(model_path, tokenizer_path, test_df, save_dir)\n",
    "    except Exception as e:\n",
    "        print(f\"Error evaluating {experiment_name}: {str(e)}\")\n",
    "        continue"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1c52d16c5ab04a7f80ab6c59b08e32b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "30893a4d61c547b6bac48d2fd81be4da": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ae64a788be92424996b1700e10cde4b3",
       "IPY_MODEL_57960d2d5e0a47dea5e9ee14be94fd78",
       "IPY_MODEL_ac90c5c5687e41a89c4808dc0468d188"
      ],
      "layout": "IPY_MODEL_83b5bc42260d4ee2a42eacb589011c26"
     }
    },
    "33b3ffa581c14eac8d31962038d4151f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "426d28dcd2fd44cbb4606da8ba677f6e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "446c9ba1505042319cc17bc2736e9697": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "46a771836bce4670b8775e658bb55dbb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "46c560ca9fb649b4bbbebc78930ef951": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "57960d2d5e0a47dea5e9ee14be94fd78": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_426d28dcd2fd44cbb4606da8ba677f6e",
      "max": 120,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6a58de6976e843a490c81acc7ce96a0e",
      "value": 0
     }
    },
    "68f85296ce91429b87a8e8ac239b9c22": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9f5fe20e905145f49e7fc057f553e82e",
       "IPY_MODEL_dd0939540863411e81579622819f579c",
       "IPY_MODEL_8cc80cf4c2a641e7a715b6f3295862c1"
      ],
      "layout": "IPY_MODEL_c3891c72d2844331a225ec4cd0024332"
     }
    },
    "6a58de6976e843a490c81acc7ce96a0e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7114a7fcc1ea4eea867d741ef6f5e762": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7d829babd3be486db9949075e1647e17": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "83b5bc42260d4ee2a42eacb589011c26": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "8cc80cf4c2a641e7a715b6f3295862c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7114a7fcc1ea4eea867d741ef6f5e762",
      "placeholder": "",
      "style": "IPY_MODEL_b649b6baf1744ef1a90e4ab78312b98c",
      "value": "2/2[00:01&lt;00:00,1.04it/s]"
     }
    },
    "9f5fe20e905145f49e7fc057f553e82e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d04d00b94a874e689621394ad560c65a",
      "placeholder": "",
      "style": "IPY_MODEL_46c560ca9fb649b4bbbebc78930ef951",
      "value": "SanityCheckingDataLoader0:100%"
     }
    },
    "ac90c5c5687e41a89c4808dc0468d188": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7d829babd3be486db9949075e1647e17",
      "placeholder": "",
      "style": "IPY_MODEL_1c52d16c5ab04a7f80ab6c59b08e32b2",
      "value": "0/120[00:00&lt;?,?it/s]"
     }
    },
    "ae64a788be92424996b1700e10cde4b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_33b3ffa581c14eac8d31962038d4151f",
      "placeholder": "",
      "style": "IPY_MODEL_446c9ba1505042319cc17bc2736e9697",
      "value": "Epoch0:0%"
     }
    },
    "b1677988c9e747639cac087311805dae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b649b6baf1744ef1a90e4ab78312b98c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c3891c72d2844331a225ec4cd0024332": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": "100%"
     }
    },
    "d04d00b94a874e689621394ad560c65a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dd0939540863411e81579622819f579c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_46a771836bce4670b8775e658bb55dbb",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b1677988c9e747639cac087311805dae",
      "value": 2
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
