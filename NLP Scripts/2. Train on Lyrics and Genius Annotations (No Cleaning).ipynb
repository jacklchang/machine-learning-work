{"cells":[{"cell_type":"markdown","source":["# Read in dependencies"],"metadata":{"id":"qxwOx7AyqtsM"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9974,"status":"ok","timestamp":1733449719698,"user":{"displayName":"Chloe Alexandria McGlynn","userId":"15171080650626567424"},"user_tz":480},"id":"EMq71VljYUei","outputId":"94d0e415-5119-45b2-e5b0-fda0c220696d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pytorch-lightning\n","  Downloading pytorch_lightning-2.4.0-py3-none-any.whl.metadata (21 kB)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.3)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n","Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.66.6)\n","Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (6.0.2)\n","Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (2024.10.0)\n","Collecting torchmetrics>=0.7.0 (from pytorch-lightning)\n","  Downloading torchmetrics-1.6.0-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (24.2)\n","Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.12.2)\n","Collecting lightning-utilities>=0.10.0 (from pytorch-lightning)\n","  Downloading lightning_utilities-0.11.9-py3-none-any.whl.metadata (5.2 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (3.11.9)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.10.0->pytorch-lightning) (75.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (2.4.4)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.3.1)\n","Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (4.0.3)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (0.2.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.18.3)\n","Downloading pytorch_lightning-2.4.0-py3-none-any.whl (815 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.2/815.2 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lightning_utilities-0.11.9-py3-none-any.whl (28 kB)\n","Downloading torchmetrics-1.6.0-py3-none-any.whl (926 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m926.4/926.4 kB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: lightning-utilities, torchmetrics, pytorch-lightning\n","Successfully installed lightning-utilities-0.11.9 pytorch-lightning-2.4.0 torchmetrics-1.6.0\n"]}],"source":["# import needed dependencies for testing PoemSum model\n","!pip install pytorch-lightning transformers torch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mRJhMcgtYZTl"},"outputs":[],"source":["# Import needed dependencies while avoiding conflicts\n","import pandas as pd\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","import pytorch_lightning as pl\n","from pytorch_lightning.callbacks import ModelCheckpoint\n","from pytorch_lightning.loggers import TensorBoardLogger\n","from transformers import (\n","    T5ForConditionalGeneration,\n","    T5TokenizerFast as T5Tokenizer,\n","    AdamW\n",")\n","import re\n","import os\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"59JdfwDxijbV"},"outputs":[],"source":["import textwrap\n","def print_summary(text, width=70):\n","    print(textwrap.fill(text, width=width))\n"]},{"cell_type":"markdown","metadata":{"id":"hcct8nQQby2J"},"source":["# Class Modules"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TCBObUD_YcPf"},"outputs":[],"source":["# Custom Dataset class from PoemSum model\n","class LyricsSummaryDataset(Dataset):\n","    def __init__(\n","        self,\n","        data: pd.DataFrame,\n","        tokenizer: T5Tokenizer,\n","        text_max_token_len: int = 2000,\n","        summary_max_token_len: int = 10000\n","    ):\n","        self.tokenizer = tokenizer\n","        self.data = data\n","        self.text_max_token_len = text_max_token_len\n","        self.summary_max_token_len = summary_max_token_len\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, index: int):\n","        data_row = self.data.iloc[index]\n","\n","        text_encoding = self.tokenizer(\n","            data_row[\"text\"],\n","            max_length=self.text_max_token_len,\n","            padding=\"max_length\",\n","            truncation=True,\n","            return_attention_mask=True,\n","            add_special_tokens=True,\n","            return_tensors=\"pt\"\n","        )\n","\n","        summary_encoding = self.tokenizer(\n","            data_row[\"summary\"],\n","            max_length=self.summary_max_token_len,\n","            padding=\"max_length\",\n","            truncation=True,\n","            return_attention_mask=True,\n","            add_special_tokens=True,\n","            return_tensors=\"pt\"\n","        )\n","\n","        labels = summary_encoding[\"input_ids\"]\n","        labels[labels == 0] = -100\n","\n","        return dict(\n","            text=data_row[\"text\"],\n","            summary=data_row[\"summary\"],\n","            text_input_ids=text_encoding[\"input_ids\"].flatten(),\n","            text_attention_mask=text_encoding[\"attention_mask\"].flatten(),\n","            labels=labels.flatten(),\n","            labels_attention_mask=summary_encoding[\"attention_mask\"].flatten()\n","        )\n","\n","# Lightning Data Module from Poem Sum\n","class LyricsSummaryDataModule(pl.LightningDataModule):\n","    def __init__(\n","        self,\n","        train_df: pd.DataFrame,\n","        val_df: pd.DataFrame,\n","        tokenizer: T5Tokenizer,\n","        batch_size: int = 8,\n","        text_max_token_len: int = 512,\n","        summary_max_token_len: int = 256\n","    ):\n","        super().__init__()\n","        self.train_df = train_df\n","        self.val_df = val_df\n","        self.batch_size = batch_size\n","        self.tokenizer = tokenizer\n","        self.text_max_token_len = text_max_token_len\n","        self.summary_max_token_len = summary_max_token_len\n","\n","    def setup(self, stage=None):\n","        self.train_dataset = LyricsSummaryDataset(\n","            self.train_df,\n","            self.tokenizer,\n","            self.text_max_token_len,\n","            self.summary_max_token_len\n","        )\n","        self.val_dataset = LyricsSummaryDataset(\n","            self.val_df,\n","            self.tokenizer,\n","            self.text_max_token_len,\n","            self.summary_max_token_len\n","        )\n","\n","    def train_dataloader(self):\n","        return DataLoader(\n","            self.train_dataset,\n","            batch_size=self.batch_size,\n","            shuffle=True,\n","            num_workers=2\n","        )\n","\n","    def val_dataloader(self):\n","        return DataLoader(\n","            self.val_dataset,\n","            batch_size=self.batch_size,\n","            shuffle=False,\n","            num_workers=2\n","        )\n","\n","# Model Class\n","class LyricsSummaryModel(pl.LightningModule):\n","    def __init__(self, model_name='t5-small'):\n","        super().__init__()\n","        self.model = T5ForConditionalGeneration.from_pretrained(model_name, return_dict=True)\n","\n","    def forward(self, input_ids, attention_mask, decoder_attention_mask, labels=None):\n","        output = self.model(\n","            input_ids,\n","            attention_mask=attention_mask,\n","            labels=labels,\n","            decoder_attention_mask=decoder_attention_mask\n","        )\n","        return output.loss, output.logits\n","\n","    def training_step(self, batch, batch_idx):\n","        loss, outputs = self(\n","            batch[\"text_input_ids\"],\n","            batch[\"text_attention_mask\"],\n","            batch[\"labels_attention_mask\"],\n","            batch[\"labels\"]\n","        )\n","        self.log(\"train_loss\", loss, prog_bar=True, logger=True)\n","        return loss\n","\n","    def validation_step(self, batch, batch_idx):\n","        loss, outputs = self(\n","            batch[\"text_input_ids\"],\n","            batch[\"text_attention_mask\"],\n","            batch[\"labels_attention_mask\"],\n","            batch[\"labels\"]\n","        )\n","        self.log(\"val_loss\", loss, prog_bar=True, logger=True)\n","        return loss\n","\n","    def configure_optimizers(self):\n","        return AdamW(self.parameters(), lr=0.00001)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22319,"status":"ok","timestamp":1733449798465,"user":{"displayName":"Chloe Alexandria McGlynn","userId":"15171080650626567424"},"user_tz":480},"id":"N5CE2vZ_YmJn","outputId":"803c38d5-5304-411b-d5c0-49aab73e2e54"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"dq9Fv1GtblFQ"},"source":["# Data Preparation\n","\n","Let's start with one artist and clean up their input file"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"43Y7qGqUFhgx"},"outputs":[],"source":["#Train on all artists\n","# Initialize an empty list to store DataFrames\n","df_list = []\n","\n","folder_path = \"/content/drive/My Drive/266 Final Project/Cleaned Song Files\"\n","# Iterate through each file in the directory\n","for filename in os.listdir(folder_path):\n","  # Check if the file is a CSV file\n","  if filename.endswith('.csv'):\n","    #Construct the full file path\n","    file_path = os.path.join(folder_path, filename)\n","    # Read the CSV file and append it to the list\n","    df = pd.read_csv(file_path)\n","    df_list.append(df)\n","\n","# Concatenate all DataFrames in the list into a single DataFrame\n","df = pd.concat(df_list, ignore_index=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":323,"status":"ok","timestamp":1733452263426,"user":{"displayName":"Chloe Alexandria McGlynn","userId":"15171080650626567424"},"user_tz":480},"id":"_yM9fTn10qpw","outputId":"7358ca45-cffa-47c3-943f-39a7be1b3680"},"outputs":[{"output_type":"stream","name":"stdout","text":["Average string length of lyrics: 1456.5506551613935\n","Min string length of lyrics: 12.0\n","Max string length of lyrics: 5686.0\n"]}],"source":["# Calculate average string length of the column\n","average_length = df['Lyrics'].str.len().mean()\n","min_length = df['Lyrics'].str.len().min()\n","max_length = df['Lyrics'].str.len().max()\n","\n","# Display the result\n","print(\"Average string length of lyrics:\", average_length)\n","print(\"Min string length of lyrics:\", min_length)\n","print(\"Max string length of lyrics:\", max_length)"]},{"cell_type":"markdown","metadata":{"id":"zhoIdvxjbrz8"},"source":["# Create and Train t5 model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ErlxaqVAnQnz"},"outputs":[],"source":["# Do this before calling create_baseline_model\n","train_val_df, test_df = train_test_split(df, test_size=0.2, random_state=42)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ELuENYcubWRr"},"outputs":[],"source":["def create_baseline_model(df, save_dir=\"checkpoints\"):\n","  # 1. Initialize model and tokenizer\n","  print(\"Initializing model and tokenizer...\")\n","  MODEL_NAME = 't5-small'\n","  tokenizer = T5Tokenizer.from_pretrained(MODEL_NAME)\n","  model = LyricsSummaryModel(MODEL_NAME)\n","\n","  # 2. Prepare data\n","  print(\"Preparing data...\")\n","\n","  # Handle missing or invalid data in 'Combined Annotations' column\n","  df['Combined Annotations'] = df['Combined Annotations'].astype(str)  # Convert to string type\n","  df['Combined Annotations'] = df['Combined Annotations'].fillna('')  # Fill missing values with empty string\n","\n","  prepared_data = pd.DataFrame({\n","      'text': df.apply(\n","          lambda x: f\"summarize lyrics and capture meaning: {x['Lyrics']}\",\n","          axis=1\n","      ),\n","      'summary': df['Combined Annotations'].apply(\n","          lambda x: f\"Meaning and themes: {' '.join(x.split()[:100])}\"\n","      )\n","  })\n","  # 3. Split data\n","  train_size = int(0.8 * len(prepared_data))\n","  train_data = prepared_data[:train_size]\n","  val_data = prepared_data[train_size:]\n","\n","  # 4. Set up data module\n","  data_module = LyricsSummaryDataModule(\n","      train_df=train_data,\n","      val_df=val_data,\n","      tokenizer=tokenizer,\n","      batch_size=2\n","  )\n","\n","  # 5. Set up trainer\n","  trainer = pl.Trainer(\n","      max_epochs=2,\n","      accumulate_grad_batches=2,\n","      gradient_clip_val=1.0,\n","      precision=16 if torch.cuda.is_available() else 32,\n","      enable_checkpointing=True,\n","      default_root_dir=save_dir\n","  )\n","\n","  # 6. Train model\n","  print(\"Starting training...\")\n","  trainer.fit(model, data_module)\n","\n","  # 9. Save model and tokenizer\n","  print(\"Saving model and tokenizer...\")\n","  drive_path = '/content/drive/MyDrive/266 Final Project/Our Models/Lyrics + Genius'\n","  os.makedirs(drive_path, exist_ok=True)\n","\n","  try:\n","      model.model.save_pretrained(drive_path)\n","      tokenizer.save_pretrained(drive_path)\n","      print(f\"Model and tokenizer successfully saved to {drive_path}\")\n","  except Exception as e:\n","      print(f\"Failed to save model and tokenizer: {e}\")\n","\n","  return model, tokenizer, trainer\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":462,"referenced_widgets":["0a4d5f81aa344041ad6b66ec9ab45af4","8aa0cb93284b41e69343cb116e8b2f14","8bbd9fda2aed43849d79fc7b100d7221","4cdd64c820f54d37aaece72bcbba2d80","18d528ea0dea4072b7c5c53e07da04d1","07f13fae261c48d08d090a29673d669c","42bb6dcb316e408388df433d5f90bf51","f67aff67986b41b7aaed7bf51704ac37","6c04dbb7e9164d1a82aed6d73c0193d5","56efc784e816492b8713eb9e61402340","a9f7ef46dd8c489ab65123b036f62fde","488d17219e47461497f2e2bc92cc4dd0","54a02b06e91b4f1aa3431de2d2d4189c","303bf69de2f446b78693f691f311409c","4215b6dd9d384be2901c31739b0e6935","d0af2a9e3e274935ac9a29a014f8fd62","49f4dab9749147a796cfe9da5c2ac973","a1918f8cb14e46bda4698507c669c935","e4310252e3514bf78e3b4cc402847244","e1610cfd4ea34d889ee41cbd3861478a","6cc170b620a64bd5b406485bbc2afe24","fb50cf10577d46ceab31b191fcbd67ac","a086f86bdd8149a9ada6c18b0e5a916b","360598ef9f454fe18ae13fb4fc32580e","b551eb3d87ba4736af07726f9a4ae569","b7e972bee1d44a7cb1cbac92d3dcffb5","5969a20bf7064d96980eec5958eb9e9b","8885f5ec52d34d39813ef09693ea6da1","91fdf62202fe4c9f8eaafa5d542a7053","94b47fe043b144d78212985843587311","40825f6612d64a749deb45e2bb101cb1","9d55fc3471654c6db589c5e0b2a856dd","a230684d1f99498cb02c31230e933fb1","e2bfea0bacf64a55b2728dcab9217bae","ef10699ad86d44a8b49209121482bc26","2214deecc6554004a7bbff1fc9cfaadd","0c7cb910e4f341a89d1b48c69c615d16","554077d04fca4d40b75bbc90edaaa48d","9e50d435cb454c35b4cbb1f2a7d3fa1a","58259619eb4c4bd98a10ba882d60e011","d2b2643ed975475495b3727cfd2ca773","485a4d7c0be94e4fb605e0572c0be19d","d105e8296e414f719fd9b3c61d9621f2","e313baddeb7a4d7399571b619d1100e2"]},"executionInfo":{"elapsed":15804388,"status":"ok","timestamp":1733398345139,"user":{"displayName":"Sahana Sankar","userId":"09821259821122047380"},"user_tz":480},"id":"k6Y50eKrOssK","outputId":"a75d1a23-781e-419f-84a6-5984904e5cfc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Initializing model and tokenizer...\n"]},{"name":"stderr","output_type":"stream","text":["INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n","INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","INFO:pytorch_lightning.callbacks.model_summary:\n","  | Name  | Type                       | Params | Mode\n","------------------------------------------------------------\n","0 | model | T5ForConditionalGeneration | 60.5 M | eval\n","------------------------------------------------------------\n","60.5 M    Trainable params\n","0         Non-trainable params\n","60.5 M    Total params\n","242.026   Total estimated model params size (MB)\n","0         Modules in train mode\n","277       Modules in eval mode\n"]},{"name":"stdout","output_type":"stream","text":["Preparing data...\n","Starting training...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0a4d5f81aa344041ad6b66ec9ab45af4","version_major":2,"version_minor":0},"text/plain":["Sanity Checking: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"488d17219e47461497f2e2bc92cc4dd0","version_major":2,"version_minor":0},"text/plain":["Training: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a086f86bdd8149a9ada6c18b0e5a916b","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e2bfea0bacf64a55b2728dcab9217bae","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=2` reached.\n"]},{"name":"stdout","output_type":"stream","text":["Saving model and tokenizer...\n","Model and tokenizer successfully saved to /content/drive/MyDrive/266 Final Project/Our Models/Lyrics + Genius\n"]}],"source":["model, tokenizer, trainer = create_baseline_model(train_val_df)"]},{"cell_type":"markdown","metadata":{"id":"fS73Kv92bvWm"},"source":["# Generate Song Summary"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jBJel-CpZ0cE"},"outputs":[],"source":["def generate_song_summary(model, tokenizer, data, song_index, max_length=150):\n","    \"\"\"Generate a summary for a single song\"\"\"\n","\n","    #training input format\n","    input_text = f\"summarize lyrics and capture meaning: {data.iloc[song_index]['Lyrics']}\"\n","\n","\n","    # Encode the text\n","    inputs = tokenizer.encode(\n","        input_text,\n","        max_length=5000,\n","        truncation=True,\n","        padding=\"max_length\",\n","        return_tensors=\"pt\"\n","    )\n","\n","    # Generate summary\n","    # The 'generate' method should be called directly on the 'model' object\n","    summary_ids = model.generate( # Removed 'model.' before generate\n","        inputs,\n","        max_length=300,\n","        min_length=100,\n","        num_beams=5,\n","        #temperature=0.9,\n","        length_penalty=0.5,\n","        early_stopping=True,\n","        no_repeat_ngram_size=2\n","    )\n","\n","    # Decode summary\n","    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n","    return summary"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22499,"status":"ok","timestamp":1733450115496,"user":{"displayName":"Chloe Alexandria McGlynn","userId":"15171080650626567424"},"user_tz":480},"id":"19VhM4y6Qt3F","outputId":"60e73132-d15c-4585-dba4-918395f810ff"},"outputs":[{"output_type":"stream","name":"stderr","text":["You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"]},{"output_type":"stream","name":"stdout","text":["Model and tokenizer loaded successfully!\n"]}],"source":["from transformers import T5ForConditionalGeneration, T5Tokenizer\n","\n","model_path = '/content/drive/My Drive/266 Final Project/Our Models/Lyrics + Genius'\n","tokenizer = T5Tokenizer.from_pretrained(model_path)\n","model = T5ForConditionalGeneration.from_pretrained(model_path)\n","\n","print(\"Model and tokenizer loaded successfully!\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"executionInfo":{"elapsed":49746,"status":"error","timestamp":1733450167412,"user":{"displayName":"Chloe Alexandria McGlynn","userId":"15171080650626567424"},"user_tz":480},"id":"G_G_ZC4-Zfv6","outputId":"35985410-2a2e-4a5b-beee-de5516599295"},"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-ffd55fe0633f>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \"\"\"\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0msummary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_song_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msong_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-14-0f68c8877848>\u001b[0m in \u001b[0;36mgenerate_song_summary\u001b[0;34m(model, tokenizer, data, song_index, max_length)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# Generate summary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# The 'generate' method should be called directly on the 'model' object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     summary_ids = model.generate( # Removed 'model.' before generate\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2245\u001b[0m             \u001b[0;31m# 13. run beam sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2246\u001b[0;31m             result = self._beam_search(\n\u001b[0m\u001b[1;32m   2247\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2248\u001b[0m                 \u001b[0mbeam_scorer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_beam_search\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, generation_config, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   3545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3546\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"past_key_values\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3547\u001b[0;31m                 model_kwargs[\"past_key_values\"] = self._temporary_reorder_cache(\n\u001b[0m\u001b[1;32m   3548\u001b[0m                     \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"past_key_values\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam_idx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3549\u001b[0m                 )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_temporary_reorder_cache\u001b[0;34m(self, past_key_values, beam_idx)\u001b[0m\n\u001b[1;32m   3319\u001b[0m         \u001b[0;31m# Standard code path: use the `Cache.reorder_cache`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3320\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3321\u001b[0;31m             \u001b[0mpast_key_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreorder_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeam_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3322\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpast_key_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/cache_utils.py\u001b[0m in \u001b[0;36mreorder_cache\u001b[0;34m(self, beam_idx)\u001b[0m\n\u001b[1;32m   1496\u001b[0m         \u001b[0;34m\"\"\"Reorders the cache for beam search, given the selected beam indices.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1497\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mself_attention_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreorder_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeam_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1498\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_attention_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreorder_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeam_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcheck_dynamic_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/cache_utils.py\u001b[0m in \u001b[0;36mreorder_cache\u001b[0;34m(self, beam_idx)\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m                 \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam_idx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# Usage example:\n","\"\"\"\n","generate_song_summary(model, tokenizer, df, song_index=0)\n","\"\"\"\n","\n","summary = generate_song_summary(model, tokenizer, df, song_index=1)\n","\n","print(df.iloc[1]['Title'])\n","print_summary(summary)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1733441987556,"user":{"displayName":"Sahana S","userId":"09133778862757081963"},"user_tz":480},"id":"CfuVF89VsKrW","outputId":"4db38bd4-9b2a-40de-cdcd-11882aaae137"},"outputs":[{"name":"stdout","output_type":"stream","text":["['Song ID', 'Title', 'Lyrics URL', 'Combined Annotations', 'Wikipedia Annotation', 'Lyrics']\n"]}],"source":["print(df.columns.tolist())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1733441987556,"user":{"displayName":"Sahana S","userId":"09133778862757081963"},"user_tz":480},"id":"0K2ZkEN8BxRi","outputId":"e476fa21-d7af-4c0f-c8cf-62101a209242"},"outputs":[{"name":"stdout","output_type":"stream","text":["This song unfolds as a poignant reflection on a troubled relationship.\n","The song’s title immediately conjures images of unfulfilled dreams and\n","broken commitments. As the track progresses, it becomes evident that\n","Drake, is addressing a woman named Hailey.  The song’s opening lines,\n","“Hailey, it’s sad that I know all the tea,” set a tone of\n","disappointment and disillusionment. Drake references “broken pinky\n","promises” and recounts how a trip to the Bahamas was marred by\n","Hailey’s actions. There’s a palpable sense of betrayal and a\n","realization that the relationship isn’t working.  Throughout the song,\n","the theme of disappointment and broken trust resurfaces. Drake\n","expresses weariness with Hailey’s apologies, indicating that he’s\n","reached a breaking point. The wordplay involving “No” in monogamy\n","suggests that the relationship has been marked by infidelity or a lack\n","of commitment.  As the song unfolds, the emotional weight becomes more\n","pronounced. Drake laments that Hailey lives in his mind, rent-free,\n","despite seemingly not reciprocating the same level of affection.\n","There’s a paradoxical feeling of being indispensable yet unmissed.\n","The song’s outro, with its repetition of “Dogs, man” and the album’s\n","title, “For All The Dogs,” hints at themes of loyalty and\n","companionship. It’s a poignant reminder that even in the face of\n","disappointment and heartache, there’s a longing for genuine connection\n","and loyalty.  This song offers a glimpse into the complexities of\n","human relationships, where promises are broken, trust is shattered,\n","and emotional scars linger. It’s a song that resonates with anyone who\n","has grappled with the aftermath of a failed love affair, a testament\n","to Drake’s ability to capture the raw emotions of his experiences in\n","his music.\n"]}],"source":["print_summary(df.iloc[1]['Combined Annotations'])\n"]},{"cell_type":"markdown","metadata":{"id":"j6R5syop1Pns"},"source":["#Evaluation"]},{"cell_type":"markdown","source":["The main differences from the self-supervised approached used in Lyrics Only model are:\n","\n","* Evaluation against reference annotations instead of between multiple generations\n","* Simplified ROUGE score calculation (comparing to reference instead of between generations)\n","* Removed consistency scoring between multiple generations\n","* Added reference annotations to the examples output\n","\n","If I run into memory issues:\n","\n","* Reduce batch_size\n","* Add more aggressive memory cleanup"],"metadata":{"id":"nnhdOmewt6mR"}},{"cell_type":"code","source":["# call saved model\n","from transformers import T5ForConditionalGeneration, T5Tokenizer\n","\n","model_path = '/content/drive/My Drive/266 Final Project/Our Models/Lyrics + Genius'\n","tokenizer = T5Tokenizer.from_pretrained(model_path)\n","model = T5ForConditionalGeneration.from_pretrained(model_path)\n","\n","print(\"Model and tokenizer loaded successfully!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z-NMXEO9rou-","executionInfo":{"status":"ok","timestamp":1733450219943,"user_tz":480,"elapsed":1326,"user":{"displayName":"Chloe Alexandria McGlynn","userId":"15171080650626567424"}},"outputId":"f94ebf76-4d3b-4c0f-83fe-dfece0ba2e26"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model and tokenizer loaded successfully!\n"]}]},{"cell_type":"code","source":["# Check that test_df was correctly initialized\n","print(test_df.shape)\n","print(test_df.columns)\n","print(test_df.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GCcN9Lo7ulWx","executionInfo":{"status":"ok","timestamp":1733452347777,"user_tz":480,"elapsed":281,"user":{"displayName":"Chloe Alexandria McGlynn","userId":"15171080650626567424"}},"outputId":"cd9d2d30-c00d-4d8a-db73-2aa58feae55c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(638, 7)\n","Index(['Song ID', 'Title', 'Lyrics URL', 'Combined Annotations',\n","       'Wikipedia Annotation', 'Lyrics', 'generated_annotation'],\n","      dtype='object')\n","      Song ID                       Title  \\\n","1029   328891              Someone for Me   \n","1001   141615  Saving All My Love for You   \n","785   8827806      What It Is (Block Boy)   \n","411   3037193             I’m Good (Blue)   \n","1105  1342410             The Way You Are   \n","\n","                                             Lyrics URL  \\\n","1029  https://genius.com/Whitney-houston-someone-for...   \n","1001  https://genius.com/Whitney-houston-saving-all-...   \n","785   https://genius.com/Doechii-what-it-is-block-bo...   \n","411   https://genius.com/David-guetta-and-bebe-rexha...   \n","1105  https://genius.com/Tears-for-fears-the-way-you...   \n","\n","                                   Combined Annotations  \\\n","1029  “Someone for Me” is the third track from Whitn...   \n","1001  “Saving All My Love for You” is a song written...   \n","785                                                   ?   \n","411   “I’m Good (Blue)” is a song by David Guetta an...   \n","1105  “The Way You Are” was the first Tears for Fear...   \n","\n","                                   Wikipedia Annotation  \\\n","1029  No Wikipedia annotation found (artist name not...   \n","1001  \"Saving All My Love for You\" is a song written...   \n","785   What It Is Block Boy is a song by American rap...   \n","411   Im Good Blue is a song by French DJ and produc...   \n","1105  The Way You Are may refer to:\\n\\n\"The Way You ...   \n","\n","                                                 Lyrics generated_annotation  \n","1029  (Someone for me) \\n(Someone for me) \\nI'm here...                  NaN  \n","1001  A few stolen moments is all that we share\\r\\nY...                  NaN  \n","785   What it is, ho? Whats up? Every good girl need...                  NaN  \n","411   Im good, yeah, Im feelin alright Baby, Ima hav...                  NaN  \n","1105  Going far, getting nowhere\\r\\nGoing far, the w...                  NaN  \n"]}]},{"cell_type":"code","source":["# Check for NaN values\n","print(\"NaN values in test_df:\")\n","print(test_df.isna().sum())\n","\n","# Check data types\n","print(\"\\nData types:\")\n","print(test_df.dtypes)\n","\n","# Clean the data\n","test_df['Lyrics'] = test_df['Lyrics'].fillna('')\n","test_df['Combined Annotations'] = test_df['Combined Annotations'].fillna('')\n","\n","# Convert to string type\n","test_df['Lyrics'] = test_df['Lyrics'].astype(str)\n","test_df['Combined Annotations'] = test_df['Combined Annotations'].astype(str)\n","\n","# Verify no empty strings that might cause issues\n","print(\"\\nNumber of empty lyrics:\", len(test_df[test_df['Lyrics'] == '']))\n","print(\"Number of empty annotations:\", len(test_df[test_df['Combined Annotations'] == '']))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NKeJaiPny6NC","executionInfo":{"status":"ok","timestamp":1733452358567,"user_tz":480,"elapsed":318,"user":{"displayName":"Chloe Alexandria McGlynn","userId":"15171080650626567424"}},"outputId":"ded6eaaa-eb09-4648-bb35-00a59dacb556"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["NaN values in test_df:\n","Song ID                   3\n","Title                     9\n","Lyrics URL               12\n","Combined Annotations      9\n","Wikipedia Annotation      9\n","Lyrics                    9\n","generated_annotation    635\n","dtype: int64\n","\n","Data types:\n","Song ID                 object\n","Title                   object\n","Lyrics URL              object\n","Combined Annotations    object\n","Wikipedia Annotation    object\n","Lyrics                  object\n","generated_annotation    object\n","dtype: object\n","\n","Number of empty lyrics: 9\n","Number of empty annotations: 9\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15037,"status":"ok","timestamp":1733450309033,"user":{"displayName":"Chloe Alexandria McGlynn","userId":"15171080650626567424"},"user_tz":480},"id":"hhbecELMDQQ1","outputId":"f59c43c8-156e-425c-e676-efcf95504691"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: bert-score in /usr/local/lib/python3.10/dist-packages (0.3.13)\n","Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from bert-score) (2.5.1+cu121)\n","Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from bert-score) (2.2.2)\n","Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from bert-score) (4.46.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bert-score) (1.26.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bert-score) (2.32.3)\n","Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.10/dist-packages (from bert-score) (4.66.6)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from bert-score) (3.8.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from bert-score) (24.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert-score) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert-score) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert-score) (2024.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (2024.10.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.0.0->bert-score) (1.3.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (0.26.3)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (2024.9.11)\n","Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (0.20.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (0.4.5)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (4.55.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (1.4.7)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (11.0.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (3.2.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score) (2024.8.30)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert-score) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0.0->bert-score) (3.0.2)\n","Requirement already satisfied: rouge-score in /usr/local/lib/python3.10/dist-packages (0.1.2)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.4.0)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score) (3.9.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.26.4)\n","Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.16.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (2024.9.11)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (4.66.6)\n"]}],"source":["# Install required package\n","!pip install bert-score\n","!pip install rouge-score\n","\n","import torch\n","import numpy as np\n","import pandas as pd\n","from typing import List, Dict, Tuple\n","from transformers import T5Tokenizer\n","from rouge_score import rouge_scorer\n","from bert_score import score\n","from tqdm import tqdm\n","\n","from bert_score import score\n","import torch\n","from sklearn.model_selection import train_test_split\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o3lBzoH2Eaui"},"outputs":[],"source":["def evaluate_supervised_model(\n","    model: T5ForConditionalGeneration,\n","    tokenizer: T5Tokenizer,\n","    test_data: pd.DataFrame,\n","    batch_size: int = 16\n",") -> Tuple[Dict[str, float], List[Dict]]:\n","    \"\"\"\n","    Evaluate supervised lyrics model comparing against Genius annotations\n","    \"\"\"\n","    model.eval()\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    model = model.to(device)\n","\n","    evaluation_results = {\n","        'content_coverage': [],\n","        'consistency_score': [],\n","        'semantic_similarity': [],\n","        'rouge1_scores': [],\n","        'rouge2_scores': [],\n","        'rougeL_scores': [],\n","        'bert_scores': []\n","    }\n","\n","    examples = []\n","    previous_bert_score = 0.0\n","\n","    for idx in tqdm(range(0, len(test_data), batch_size)):\n","        batch_lyrics = test_data['Lyrics'].iloc[idx:idx + batch_size].tolist()\n","        batch_annotations = test_data['Combined Annotations'].iloc[idx:idx + batch_size].tolist()\n","\n","        # Generate summaries\n","        inputs = tokenizer(\n","            [f\"summarize lyrics and capture meaning: {lyric}\" for lyric in batch_lyrics],\n","            padding=True,\n","            truncation=True,\n","            max_length=512,\n","            return_tensors=\"pt\"\n","        ).to(device)\n","\n","        with torch.no_grad():\n","            outputs = model.generate(\n","                input_ids=inputs['input_ids'],\n","                attention_mask=inputs['attention_mask'],\n","                max_length=150,\n","                min_length=50,\n","                num_beams=4,\n","                do_sample=True,\n","                temperature=0.7,\n","                top_k=50,\n","                no_repeat_ngram_size=3,\n","                length_penalty=1.0,\n","                repetition_penalty=1.2\n","            )\n","\n","            generated_summaries = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n","\n","        # Evaluate each summary against its reference annotation\n","        for i in range(len(generated_summaries)):\n","            original_lyric = batch_lyrics[i]\n","            generated_summary = generated_summaries[i]\n","            reference_annotation = batch_annotations[i]\n","\n","            # Content Coverage (between summary and lyrics)\n","            coverage_score = calculate_content_coverage(original_lyric, generated_summary)\n","            evaluation_results['content_coverage'].append(coverage_score)\n","\n","            # Semantic Similarity (between summary and lyrics)\n","            semantic_score = calculate_semantic_similarity(original_lyric, generated_summary)\n","            evaluation_results['semantic_similarity'].append(semantic_score)\n","\n","            # ROUGE Scores (between generated summary and reference annotation)\n","            rouge_scores = calculate_rouge_scores([generated_summary, reference_annotation])\n","            evaluation_results['rouge1_scores'].append(rouge_scores['rouge1'])\n","            evaluation_results['rouge2_scores'].append(rouge_scores['rouge2'])\n","            evaluation_results['rougeL_scores'].append(rouge_scores['rougeL'])\n","\n","            # BERTScore (between generated summary and reference annotation)\n","            if i % 8 == 0:  # Compute less frequently to save time\n","                P, R, F1 = score([generated_summary], [reference_annotation], lang='en', verbose=False)\n","                previous_bert_score = F1.mean().item()\n","            evaluation_results['bert_scores'].append(previous_bert_score)\n","\n","            # Store examples\n","            if len(examples) < 5:\n","                examples.append({\n","                    'lyrics': original_lyric,\n","                    'reference_annotation': reference_annotation,\n","                    'generated_summary': generated_summary,\n","                    'metrics': {\n","                        'content_coverage': coverage_score,\n","                        'semantic_similarity': semantic_score,\n","                        'rouge1': rouge_scores['rouge1'],\n","                        'rouge2': rouge_scores['rouge2'],\n","                        'rougeL': rouge_scores['rougeL'],\n","                        'bert_score': previous_bert_score\n","                    }\n","                })\n","\n","        # Memory cleanup\n","        if idx % 5 == 0:\n","            torch.cuda.empty_cache()\n","\n","    # Aggregate results\n","    metrics = {\n","        'avg_content_coverage': np.mean(evaluation_results['content_coverage']),\n","        'avg_semantic_similarity': np.mean(evaluation_results['semantic_similarity']),\n","        'avg_rouge1': np.mean(evaluation_results['rouge1_scores']),\n","        'avg_rouge2': np.mean(evaluation_results['rouge2_scores']),\n","        'avg_rougeL': np.mean(evaluation_results['rougeL_scores']),\n","        'avg_bert_score': np.mean(evaluation_results['bert_scores'])\n","    }\n","\n","    return metrics, examples\n","\n","def calculate_rouge_scores(texts: List[str]) -> Dict[str, float]:\n","    \"\"\"Calculate ROUGE scores between texts\"\"\"\n","    rouge_scorer_obj = rouge_scorer.RougeScorer(\n","        ['rouge1', 'rouge2', 'rougeL'],\n","        use_stemmer=True\n","    )\n","\n","    # For supervised evaluation, compare generated summary to reference\n","    score = rouge_scorer_obj.score(texts[0], texts[1])\n","\n","    return {\n","        'rouge1': score['rouge1'].fmeasure,\n","        'rouge2': score['rouge2'].fmeasure,\n","        'rougeL': score['rougeL'].fmeasure\n","    }\n","\n","def calculate_content_coverage(lyrics: str, summary: str) -> float:\n","    \"\"\"Calculate content coverage between lyrics and summary\"\"\"\n","    # Handle NaN or float values\n","    if isinstance(lyrics, float) or isinstance(summary, float):\n","        return 0.0\n","\n","    try:\n","        lyrics_tokens = set(str(lyrics).lower().split())\n","        summary_tokens = set(str(summary).lower().split())\n","        overlap = len(lyrics_tokens.intersection(summary_tokens))\n","        coverage = overlap / len(lyrics_tokens) if lyrics_tokens else 0.0\n","        return coverage\n","    except Exception as e:\n","        print(f\"Error processing lyrics/summary: {e}\")\n","        return 0.0\n","\n","def calculate_semantic_similarity(lyrics: str, summary: str) -> float:\n","    \"\"\"Calculate semantic similarity using token overlap\"\"\"\n","    # Handle NaN or float values\n","    if isinstance(lyrics, float) or isinstance(summary, float):\n","        return 0.0\n","\n","    try:\n","        lyrics_tokens = set(str(lyrics).lower().split())\n","        summary_tokens = set(str(summary).lower().split())\n","        intersection = len(lyrics_tokens.intersection(summary_tokens))\n","        union = len(lyrics_tokens.union(summary_tokens))\n","        return intersection / union if union > 0 else 0.0\n","    except Exception as e:\n","        print(f\"Error processing lyrics/summary: {e}\")\n","        return 0.0\n","\n","def print_evaluation_results(metrics: Dict[str, float], examples: List[Dict]):\n","    \"\"\"Print evaluation results and examples\"\"\"\n","    print(\"\\nEvaluation Results:\")\n","    print(f\"Average Content Coverage: {metrics['avg_content_coverage']:.3f}\")\n","    print(f\"Average Semantic Similarity: {metrics['avg_semantic_similarity']:.3f}\")\n","    print(f\"Average ROUGE-1: {metrics['avg_rouge1']:.3f}\")\n","    print(f\"Average ROUGE-2: {metrics['avg_rouge2']:.3f}\")\n","    print(f\"Average ROUGE-L: {metrics['avg_rougeL']:.3f}\")\n","    print(f\"Average BERTScore: {metrics['avg_bert_score']:.3f}\")\n","\n","    print(\"\\nExample Generations:\")\n","    for i, example in enumerate(examples, 1):\n","        print(f\"\\nExample {i}:\")\n","        print(f\"Original Lyrics (truncated): {example['lyrics'][:200]}...\")\n","        print(f\"\\nReference Annotation: {example['reference_annotation']}\")\n","        print(f\"\\nGenerated Summary: {example['generated_summary']}\")\n","        print(\"\\nMetrics:\")\n","        for metric, value in example['metrics'].items():\n","            print(f\"{metric}: {value:.3f}\")\n","\n","# Usage example:\n","def run_evaluation(model_path: str, test_df: pd.DataFrame):\n","    \"\"\"Run complete evaluation pipeline\"\"\"\n","    tokenizer = T5Tokenizer.from_pretrained(model_path)\n","    model = T5ForConditionalGeneration.from_pretrained(model_path)\n","    print(\"Model and tokenizer loaded successfully!\")\n","\n","    metrics, examples = evaluate_supervised_model(\n","        model,\n","        tokenizer,\n","        test_data=test_df,\n","        batch_size=16\n","    )\n","\n","    print_evaluation_results(metrics, examples)\n","    return metrics, examples"]},{"cell_type":"code","source":["# Run the evaluation\n","metrics, examples = run_evaluation(model_path, test_df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3OTXSYsxuLtQ","executionInfo":{"status":"ok","timestamp":1733457069512,"user_tz":480,"elapsed":4643288,"user":{"displayName":"Chloe Alexandria McGlynn","userId":"15171080650626567424"}},"outputId":"09074828-6d67-44f1-c82d-48f1392f5e55"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model and tokenizer loaded successfully!\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/40 [00:00<?, ?it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","  2%|▎         | 1/40 [01:56<1:15:27, 116.09s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","  5%|▌         | 2/40 [03:45<1:10:54, 111.96s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","  8%|▊         | 3/40 [05:54<1:13:55, 119.88s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"," 10%|█         | 4/40 [08:12<1:16:14, 127.07s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"," 12%|█▎        | 5/40 [10:17<1:13:37, 126.23s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"," 15%|█▌        | 6/40 [12:10<1:08:57, 121.69s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"," 18%|█▊        | 7/40 [13:56<1:04:06, 116.56s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"," 20%|██        | 8/40 [15:53<1:02:16, 116.77s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"," 22%|██▎       | 9/40 [17:42<59:08, 114.47s/it]  Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"," 25%|██▌       | 10/40 [19:30<56:07, 112.26s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"," 28%|██▊       | 11/40 [21:31<55:36, 115.04s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"," 30%|███       | 12/40 [23:37<55:16, 118.45s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"," 32%|███▎      | 13/40 [25:54<55:48, 124.02s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"," 35%|███▌      | 14/40 [27:36<50:52, 117.42s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"," 38%|███▊      | 15/40 [29:19<47:02, 112.90s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"," 40%|████      | 16/40 [31:06<44:28, 111.19s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"," 42%|████▎     | 17/40 [32:44<41:05, 107.18s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"," 45%|████▌     | 18/40 [34:45<40:48, 111.30s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"," 48%|████▊     | 19/40 [37:05<42:00, 120.03s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"," 50%|█████     | 20/40 [39:00<39:30, 118.53s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"," 52%|█████▎    | 21/40 [41:27<40:12, 127.00s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"," 55%|█████▌    | 22/40 [43:43<38:57, 129.86s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"," 57%|█████▊    | 23/40 [45:31<34:52, 123.07s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"," 60%|██████    | 24/40 [47:42<33:31, 125.73s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"," 62%|██████▎   | 25/40 [49:40<30:50, 123.40s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"," 65%|██████▌   | 26/40 [51:21<27:11, 116.54s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"," 68%|██████▊   | 27/40 [53:17<25:13, 116.44s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"," 70%|███████   | 28/40 [55:06<22:49, 114.16s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"," 72%|███████▎  | 29/40 [56:53<20:31, 111.95s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"," 75%|███████▌  | 30/40 [58:46<18:44, 112.45s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"," 78%|███████▊  | 31/40 [1:00:27<16:20, 108.94s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"," 80%|████████  | 32/40 [1:02:16<14:30, 108.83s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"," 82%|████████▎ | 33/40 [1:03:56<12:23, 106.21s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"," 85%|████████▌ | 34/40 [1:05:33<10:21, 103.55s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"," 88%|████████▊ | 35/40 [1:07:15<08:34, 102.98s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"," 90%|█████████ | 36/40 [1:09:23<07:21, 110.43s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"," 92%|█████████▎| 37/40 [1:11:18<05:35, 111.94s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"," 95%|█████████▌| 38/40 [1:13:17<03:48, 114.18s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"," 98%|█████████▊| 39/40 [1:15:20<01:56, 116.54s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","100%|██████████| 40/40 [1:17:21<00:00, 116.04s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","Evaluation Results:\n","Average Content Coverage: 0.121\n","Average Semantic Similarity: 0.095\n","Average ROUGE-1: 0.213\n","Average ROUGE-2: 0.043\n","Average ROUGE-L: 0.135\n","Average BERTScore: 0.810\n","\n","Example Generations:\n","\n","Example 1:\n","Original Lyrics (truncated): (Someone for me) \n","(Someone for me) \n","I'm here alone on a Friday night \n","Waiting here beside the phone \n","The TV, radio, and me \n","Really ain't been getting along \n","\n","I wish that I could find a way \n","\n","To party ...\n","\n","Reference Annotation: “Someone for Me” is the third track from Whitney Houston’s debut self-titled studio album,  , written by Raymond Jones & Freddie Washington. It appeared as the B-side to Houston’s 1985 single, “Thinking About You”.\n","\n","Generated Summary: Meaning and themes: “Curricus” is a song about a woman who has been dating for a while. The song is based on a relationship with a man who is not just a singer, but a person who can be a part of a dream. It’s the first time this song has been re-released.\n","\n","Metrics:\n","content_coverage: 0.102\n","semantic_similarity: 0.085\n","rouge1: 0.154\n","rouge2: 0.000\n","rougeL: 0.088\n","bert_score: 0.842\n","\n","Example 2:\n","Original Lyrics (truncated): A few stolen moments is all that we share\r\n","You've got your family and they need you there. \n","Though I try to resist being last on your list. \n","But no other man's gonna do. \n","So I'm saving all my love for...\n","\n","Reference Annotation: “Saving All My Love for You” is a song written by Michael Masser and Gerry Goffin with arrangement by Gene Page. It was originally a minor hit for Marilyn McCoo and Billy Davis Jr. in 1978 on their album Marilyn & Billy (although Davis’ voice was not heard on their version).   Whitney Houston released her cover of this song as the second single from her self-titled debut album. The song topped Billboard Hot 100, becoming Houston’s first #1 on the chart. The song has sold over 3 million copies worldwide.\n","\n","Generated Summary: Meaning and themes: “SAVE All My Love” is a song that captures the essence of a woman’s love. The song is based on a story from a friend’s childhood. It’s the first time the song has been re-released.\n","\n","Metrics:\n","content_coverage: 0.100\n","semantic_similarity: 0.086\n","rouge1: 0.346\n","rouge2: 0.122\n","rougeL: 0.226\n","bert_score: 0.842\n","\n","Example 3:\n","Original Lyrics (truncated): What it is, ho? Whats up? Every good girl needs a little thug Every block boy needs a little love If you put it down, Ima pick it up, up, up Cant you just see, its just me and you? Panoramic view, tha...\n","\n","Reference Annotation: ?\n","\n","Generated Summary: Meaning and themes:. The song is based on the lyrics of the album. It was released in June 2014, and has been re-released on the album’s release date. The track features a mix of rap, rap and rap.\n","\n","Metrics:\n","content_coverage: 0.033\n","semantic_similarity: 0.030\n","rouge1: 0.000\n","rouge2: 0.000\n","rougeL: 0.000\n","bert_score: 0.842\n","\n","Example 4:\n","Original Lyrics (truncated): Im good, yeah, Im feelin alright Baby, Ima have the best fuckin night of my life And wherever it takes me, Im down for the ride Baby, dont you know Im good, yeah, Im feelin alright Cause Im good, yeah...\n","\n","Reference Annotation: “I’m Good (Blue)” is a song by David Guetta and Bebe Rexha, becoming their second collaboration to feature only them together, with their first being 2014’s   An early version of the song appeared online in May of 2021. The released version features   vocals from Rexha, as well as different instrumental production.   by Eiffel 65 is interpolated heavily, both instrumentally during the chorus, as well as the melody that Bebe Rexha sings the lyrics in.\n","\n","Generated Summary: Meaning and themes: “I feelin alright Baby” is a single from the album. It’s based on the lyrics of the song. The song was originally released on the same day as the song “I Feelin Alright Baby”.\n","\n","Metrics:\n","content_coverage: 0.075\n","semantic_similarity: 0.059\n","rouge1: 0.298\n","rouge2: 0.089\n","rougeL: 0.211\n","bert_score: 0.842\n","\n","Example 5:\n","Original Lyrics (truncated): Going far, getting nowhere\r\n","Going far, the way you are\r\n","Going far, getting nowhere\r\n","Going far, the way you are\n","\n","Going far, getting nowhere\n","\n","The way you are\n","\n","\n","\n","Going far, getting nowhere\n","\n","The way you a...\n","\n","Reference Annotation: “The Way You Are” was the first Tears for Fears song that songwriter Roland Orzabal wrote after the release of the band’s hugely successful debut album,  . As the band was at that time very hot (i.e., marketable) in the wake of  , their record company was eager to release any new material they had, and so the band set about polishing and releasing “The Way You Are” as a single. The song only reached #24 in the charts, however, a ranking Orzabal   “reflected how good it was” (namely, not first-tier).  In hindsight, Tears for Fears and their collaborators   “The Way You Are” a second-rate song, and regret the amount of work they put into it and its release as a single. The track was later included on the 2014 Super Deluxe Edition Box Set of  , although it was written and released before that second album of the band’s.\n","\n","Generated Summary: Meaning and themes: This song is based on the lyrics of the song. The song was originally written by a friend of the same name, and has been re-released in a similar way to the one of the songs.\n","\n","Metrics:\n","content_coverage: 0.188\n","semantic_similarity: 0.132\n","rouge1: 0.250\n","rouge2: 0.042\n","rougeL: 0.167\n","bert_score: 0.842\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"markdown","metadata":{"id":"shpepSjAjoOK"},"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"collapsed_sections":["fS73Kv92bvWm"]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"07f13fae261c48d08d090a29673d669c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a4d5f81aa344041ad6b66ec9ab45af4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8aa0cb93284b41e69343cb116e8b2f14","IPY_MODEL_8bbd9fda2aed43849d79fc7b100d7221","IPY_MODEL_4cdd64c820f54d37aaece72bcbba2d80"],"layout":"IPY_MODEL_18d528ea0dea4072b7c5c53e07da04d1"}},"0c7cb910e4f341a89d1b48c69c615d16":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d105e8296e414f719fd9b3c61d9621f2","placeholder":"​","style":"IPY_MODEL_e313baddeb7a4d7399571b619d1100e2","value":" 239/239 [09:48&lt;00:00,  0.41it/s]"}},"18d528ea0dea4072b7c5c53e07da04d1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"2214deecc6554004a7bbff1fc9cfaadd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_d2b2643ed975475495b3727cfd2ca773","max":239,"min":0,"orientation":"horizontal","style":"IPY_MODEL_485a4d7c0be94e4fb605e0572c0be19d","value":239}},"303bf69de2f446b78693f691f311409c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e4310252e3514bf78e3b4cc402847244","max":954,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e1610cfd4ea34d889ee41cbd3861478a","value":954}},"360598ef9f454fe18ae13fb4fc32580e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8885f5ec52d34d39813ef09693ea6da1","placeholder":"​","style":"IPY_MODEL_91fdf62202fe4c9f8eaafa5d542a7053","value":"Validation DataLoader 0: 100%"}},"40825f6612d64a749deb45e2bb101cb1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4215b6dd9d384be2901c31739b0e6935":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6cc170b620a64bd5b406485bbc2afe24","placeholder":"​","style":"IPY_MODEL_fb50cf10577d46ceab31b191fcbd67ac","value":" 954/954 [2:20:22&lt;00:00,  0.11it/s, v_num=1, train_loss=3.810, val_loss=3.530]"}},"42bb6dcb316e408388df433d5f90bf51":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"485a4d7c0be94e4fb605e0572c0be19d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"488d17219e47461497f2e2bc92cc4dd0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_54a02b06e91b4f1aa3431de2d2d4189c","IPY_MODEL_303bf69de2f446b78693f691f311409c","IPY_MODEL_4215b6dd9d384be2901c31739b0e6935"],"layout":"IPY_MODEL_d0af2a9e3e274935ac9a29a014f8fd62"}},"49f4dab9749147a796cfe9da5c2ac973":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4cdd64c820f54d37aaece72bcbba2d80":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_56efc784e816492b8713eb9e61402340","placeholder":"​","style":"IPY_MODEL_a9f7ef46dd8c489ab65123b036f62fde","value":" 2/2 [00:09&lt;00:00,  0.22it/s]"}},"54a02b06e91b4f1aa3431de2d2d4189c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_49f4dab9749147a796cfe9da5c2ac973","placeholder":"​","style":"IPY_MODEL_a1918f8cb14e46bda4698507c669c935","value":"Epoch 1: 100%"}},"554077d04fca4d40b75bbc90edaaa48d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"56efc784e816492b8713eb9e61402340":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"58259619eb4c4bd98a10ba882d60e011":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5969a20bf7064d96980eec5958eb9e9b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"6c04dbb7e9164d1a82aed6d73c0193d5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6cc170b620a64bd5b406485bbc2afe24":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8885f5ec52d34d39813ef09693ea6da1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8aa0cb93284b41e69343cb116e8b2f14":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_07f13fae261c48d08d090a29673d669c","placeholder":"​","style":"IPY_MODEL_42bb6dcb316e408388df433d5f90bf51","value":"Sanity Checking DataLoader 0: 100%"}},"8bbd9fda2aed43849d79fc7b100d7221":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_f67aff67986b41b7aaed7bf51704ac37","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6c04dbb7e9164d1a82aed6d73c0193d5","value":2}},"91fdf62202fe4c9f8eaafa5d542a7053":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"94b47fe043b144d78212985843587311":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d55fc3471654c6db589c5e0b2a856dd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e50d435cb454c35b4cbb1f2a7d3fa1a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a086f86bdd8149a9ada6c18b0e5a916b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_360598ef9f454fe18ae13fb4fc32580e","IPY_MODEL_b551eb3d87ba4736af07726f9a4ae569","IPY_MODEL_b7e972bee1d44a7cb1cbac92d3dcffb5"],"layout":"IPY_MODEL_5969a20bf7064d96980eec5958eb9e9b"}},"a1918f8cb14e46bda4698507c669c935":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a230684d1f99498cb02c31230e933fb1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a9f7ef46dd8c489ab65123b036f62fde":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b551eb3d87ba4736af07726f9a4ae569":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_94b47fe043b144d78212985843587311","max":239,"min":0,"orientation":"horizontal","style":"IPY_MODEL_40825f6612d64a749deb45e2bb101cb1","value":239}},"b7e972bee1d44a7cb1cbac92d3dcffb5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9d55fc3471654c6db589c5e0b2a856dd","placeholder":"​","style":"IPY_MODEL_a230684d1f99498cb02c31230e933fb1","value":" 239/239 [09:34&lt;00:00,  0.42it/s]"}},"d0af2a9e3e274935ac9a29a014f8fd62":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"d105e8296e414f719fd9b3c61d9621f2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d2b2643ed975475495b3727cfd2ca773":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e1610cfd4ea34d889ee41cbd3861478a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e2bfea0bacf64a55b2728dcab9217bae":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ef10699ad86d44a8b49209121482bc26","IPY_MODEL_2214deecc6554004a7bbff1fc9cfaadd","IPY_MODEL_0c7cb910e4f341a89d1b48c69c615d16"],"layout":"IPY_MODEL_554077d04fca4d40b75bbc90edaaa48d"}},"e313baddeb7a4d7399571b619d1100e2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e4310252e3514bf78e3b4cc402847244":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef10699ad86d44a8b49209121482bc26":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9e50d435cb454c35b4cbb1f2a7d3fa1a","placeholder":"​","style":"IPY_MODEL_58259619eb4c4bd98a10ba882d60e011","value":"Validation DataLoader 0: 100%"}},"f67aff67986b41b7aaed7bf51704ac37":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fb50cf10577d46ceab31b191fcbd67ac":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}